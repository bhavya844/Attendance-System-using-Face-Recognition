{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7jNqxLZzqHx"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Face_Recognition/cleaned_256_employee_cropped_face_images.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/drive/MyDrive/cleaned_256_employee_cropped_face_images\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-facenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHaIu1Pz8Ee",
        "outputId": "dc45e40a-2479-4f6c-bae2-3f7e053b66e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-facenet\n",
            "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mtcnn (from keras-facenet)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras-facenet) (2.12.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras-facenet) (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn->keras-facenet) (1.22.4)\n",
            "Building wheels for collected packages: keras-facenet\n",
            "  Building wheel for keras-facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10370 sha256=b925aa7fd4c00dd607ac2f1178a12575ef2d9549d3ec73a117acc2b667e6d2ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/d8/a9/85cf04ea29321d2afcb82c0caaafdca9195385f9d68cbc7185\n",
            "Successfully built keras-facenet\n",
            "Installing collected packages: mtcnn, keras-facenet\n",
            "Successfully installed keras-facenet-0.3.2 mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_facenet import FaceNet\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate embeddings for a given image\n",
        "\n",
        "def generate_embedding(image):\n",
        "\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    embeddings = model.embeddings(image)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the FaceNet model\n",
        "\n",
        "model = FaceNet()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Directory paths for training and test data\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/cleaned_256_employee_cropped_face_images/256_employee_cropped_face_images'\n",
        "\n",
        "# test_data_dir = '/home/ad.rapidops.com/harshal.raut/Documents/Face Recognition/Train_Validation_Dataset/Validation_Dataset/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a directory to store the embeddings\n",
        "\n",
        "train_output_dir = '/content/drive/MyDrive/new_embedding_256_cleaned_cropped_data'\n",
        "\n",
        "os.makedirs(train_output_dir, exist_ok=True)\n",
        "\n",
        "# test_output_dir = '/home/ad.rapidops.com/harshal.raut/Documents/Face Recognition/embeddings/test/'\n",
        "\n",
        "# os.makedirs(test_output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate embeddings for test data and save them to disk\n",
        "\n",
        "# for class_folder in os.listdir(test_data_dir):\n",
        "\n",
        "#     class_path = os.path.join(test_data_dir, class_folder)\n",
        "\n",
        "#     embeddings = []\n",
        "\n",
        "#     if os.path.isdir(class_path):\n",
        "\n",
        "#         for image_name in os.listdir(class_path):\n",
        "\n",
        "#             image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "#             image = cv2.imread(image_path)\n",
        "\n",
        "#             embedding = generate_embedding(image)\n",
        "\n",
        "#             embeddings.append(embedding)\n",
        "\n",
        "#         output_dir = test_output_dir + class_folder\n",
        "\n",
        "#         os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#         output_path = os.path.join(output_dir, f'test_{class_folder}.npy')\n",
        "\n",
        "#         np.save(output_path, embeddings)\n",
        "\n",
        "\n",
        "\n",
        "# Generate embeddings for training data and save them to disk\n",
        "\n",
        "for class_folder in os.listdir(train_data_dir):\n",
        "\n",
        "    class_path = os.path.join(train_data_dir, class_folder)\n",
        "\n",
        "    embeddings = []\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "\n",
        "        for image_name in os.listdir(class_path):\n",
        "\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            embedding = generate_embedding(image)\n",
        "\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        output_dir = train_output_dir\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        output_path = os.path.join(output_dir, f'train_{class_folder}.npy')\n",
        "\n",
        "        np.save(output_path, embeddings)"
      ],
      "metadata": {
        "id": "vigd2cuDz937"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}